{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7398091e",
   "metadata": {},
   "source": [
    "### Code to be followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20401332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/raymin_env_qwen/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Random seed \"\"\"\n",
    "from transformers import set_seed\n",
    "set_seed(11207330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07925126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   0%|          | 0/900 [00:00<?, ?example/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'visual'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 242\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    241\u001b[39m     set_seed(\u001b[32m11207330\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 222\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m#tensor_type = \"bf16\" # \"bf16\", \"auto\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Load dataset \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m dataset = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    225\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Load model \"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(dataset_name_or_path, prompt_template_path)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m example\n\u001b[32m    177\u001b[39m dataset = load_dataset(\n\u001b[32m    178\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    179\u001b[39m                 data_files=dataset_name_or_path,\n\u001b[32m    180\u001b[39m                 split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m             )\n\u001b[32m    183\u001b[39m return_dataset = Dataset.from_list([\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m             \u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, desc=\u001b[33m\"\u001b[39m\u001b[33mProcessing dataset\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    186\u001b[39m         ])\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m return_dataset\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 170\u001b[39m, in \u001b[36mload_data.<locals>._preprocess\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m    166\u001b[39m example[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m] = example[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# anwer to index: 這邊是用 0,1,2,3來表示答案\u001b[39;00m\n\u001b[32m    167\u001b[39m example[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m] = prompt_template.format(question=example[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    169\u001b[39m example[\u001b[33m\"\u001b[39m\u001b[33mtemplate_prompt\u001b[39m\u001b[33m\"\u001b[39m] = get_template_response(\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     image_path=\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvisual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m    171\u001b[39m     audio_path=example[\u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    172\u001b[39m     question=example[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    173\u001b[39m )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m example\n",
      "\u001b[31mKeyError\u001b[39m: 'visual'"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "# from transformers import AutoProcessor, AutoModel\n",
    "from typing import Literal, Union, List\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from transformers import Qwen2_5OmniForConditionalGeneration, Qwen2_5OmniProcessor\n",
    "from qwen_omni_utils import process_mm_info\n",
    "from transformers import set_seed\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def clear_resources(name: str) -> None:\n",
    "    # if hasattr(self, name):\n",
    "    #     delattr(self, name)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def calculate_metrics(\n",
    "    all_choices: list,\n",
    "    all_answers: list,\n",
    "    all_response: list,\n",
    "    all_index2ans: list = None,\n",
    "    allow_random: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"calculate_metrics\"\"\"\n",
    "    if all_index2ans is None:\n",
    "        all_index2ans = [None] * len(all_response)\n",
    "\n",
    "    predictions = [\n",
    "        parse_multi_choice_response(response, all_choices, index2ans, allow_random)\n",
    "        for response, index2ans in zip(all_response, all_index2ans)\n",
    "    ]\n",
    "\n",
    "    accuracy = accuracy_score(all_answers, predictions)\n",
    "    f1 = f1_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "    precision = precision_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "    recall = recall_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "def parse_multi_choice_response(\n",
    "    response: str,\n",
    "    all_choices: list = [\"A\", \"B\", \"C\", \"D\"],\n",
    "    index2ans: dict = None,\n",
    "    allow_random: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"parse_multi_choice_response\"\"\"\n",
    "    for char in [',', '.', '!', '?', ';', ':', \"'\"]:\n",
    "        response = response.strip(char)\n",
    "    response = \" \" + response + \" \"\n",
    "\n",
    "    index_ans = True\n",
    "    ans_with_brack = False\n",
    "    candidates = []\n",
    "    for choice in all_choices:\n",
    "        if f'({choice})' in response:\n",
    "            candidates.append(choice)\n",
    "            ans_with_brack = True\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        for choice in all_choices:\n",
    "            if f' {choice} ' in response:\n",
    "                candidates.append(choice)\n",
    "\n",
    "    if index2ans is not None and len(candidates) == 0 and len(response.split()) > 5:\n",
    "        for index, ans in index2ans.items():\n",
    "            if ans and ans.lower() in response.lower():\n",
    "                candidates.append(index)\n",
    "                index_ans = False\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        if allow_random:\n",
    "            pred_index = random.choice(all_choices)\n",
    "        else:\n",
    "            pred_index = \"\"\n",
    "\n",
    "    elif len(candidates) > 1:\n",
    "        start_indexes = []\n",
    "        if index_ans:\n",
    "            if ans_with_brack:\n",
    "                for can in candidates:\n",
    "                    index = response.rfind(f'({can})')\n",
    "                    start_indexes.append(index)\n",
    "            else:\n",
    "                for can in candidates:\n",
    "                    index = response.rfind(f\" {can} \")\n",
    "                    start_indexes.append(index)\n",
    "        else:\n",
    "            for can in candidates:\n",
    "                index = response.lower().rfind(index2ans[can].lower())\n",
    "                start_indexes.append(index)\n",
    "\n",
    "        pred_index = candidates[np.argmax(start_indexes)]\n",
    "    else:\n",
    "        pred_index = candidates[0]\n",
    "\n",
    "    return pred_index\n",
    "\n",
    "def get_template_response(image_path: str, audio_path: str, question: str) -> list:\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    user_content = [] # List[Dict[str, Any]]\n",
    "    if audio_path is not None:\n",
    "        user_content.append({\n",
    "            \"type\": \"audio\",\n",
    "            \"audio\": audio_path\n",
    "        })\n",
    "    if image_path is not None:\n",
    "        user_content.append({\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image_path\n",
    "        })\n",
    "    user_content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": question\n",
    "    })\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_content\n",
    "    }\n",
    "    return [system_msg, user_msg]\n",
    "\n",
    "def load_data(dataset_name_or_path: str, \n",
    "              prompt_template_path: str = None):\n",
    "    \"\"\" Init: multiple choices answer \"\"\"\n",
    "    all_choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    \n",
    "    \"\"\" Init: prompt template\"\"\"\n",
    "    if prompt_template_path is not None:\n",
    "        try:\n",
    "            with Path(prompt_template_path).open(\"r\", encoding=\"utf-8\") as file:\n",
    "                prompt_template = file.read()\n",
    "        except (FileNotFoundError, IOError) as e:\n",
    "            raise RuntimeError(f\"Failed to load the prompt template: {e}\") from e\n",
    "    else:\n",
    "        prompt_template = \"{question}\"\n",
    "\n",
    "    \n",
    "    \"\"\" preprocess function: use the prompt template to format the question \"\"\"\n",
    "    def _preprocess(example):\n",
    "        example[\"question\"] = (\n",
    "            f\"{example['instruction']}\\n\"\n",
    "            + f\"{example['question']}\\n\"\n",
    "            + \"\".join(example[f\"option{i + 1}\"] for i in range(len(all_choices)))\n",
    "        )\n",
    "        example[\"answer\"] = example[\"answer\"].replace(\"A\", \"0\").replace(\"B\", \"1\").replace(\"C\", \"2\").replace(\"D\", \"3\") # anwer to index: 這邊是用 0,1,2,3來表示答案\n",
    "        example[\"question\"] = prompt_template.format(question=example[\"question\"])\n",
    "        \n",
    "        example[\"template_prompt\"] = get_template_response(\n",
    "            image_path=example[\"visual\"],\n",
    "            audio_path=example[\"audio\"],\n",
    "            question=example[\"question\"]\n",
    "        )\n",
    "        \n",
    "        return example\n",
    "    \n",
    "    dataset = load_dataset(\n",
    "                    \"json\",\n",
    "                    data_files=dataset_name_or_path,\n",
    "                    split=\"train\",\n",
    "                )\n",
    "    \n",
    "    return_dataset = Dataset.from_list([\n",
    "                _preprocess(example)\n",
    "                for example in tqdm(dataset, desc=\"Processing dataset\", unit=\"example\")\n",
    "            ])\n",
    "    \n",
    "    return return_dataset\n",
    "\n",
    "def load_model(model_name_or_path: Literal[\"Qwen/Qwen2.5-Omni-7B\" , \"Qwen/Qwen2.5-Omni-3B\"]):\n",
    "\n",
    "    # Load with optimizations\n",
    "    print(f\"Loading {model_name_or_path}\")\n",
    "    \n",
    "    model = Qwen2_5OmniForConditionalGeneration.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        torch_dtype=torch.bfloat16, # Use BF16\n",
    "        device_map=\"auto\",         # Auto-distribute across GPUs\n",
    "        #attn_implementation=\"flash_attention_2\" # Use Flash Attention 2\n",
    "    )\n",
    "    processor = Qwen2_5OmniProcessor.from_pretrained(model_name_or_path)\n",
    "    return model, processor\n",
    "\n",
    "def evaluate(model, processor, dataset):\n",
    "    ###############\n",
    "    start_time = time.time()\n",
    "    \"\"\" write your evaluation code here\"\"\"\n",
    "    end_time = time.time()\n",
    "    ###############\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \"\"\" Parameter \"\"\"\n",
    "    USE_AUDIO_IN_VIDEO_FLAG = False\n",
    "    dataset_name_or_path = \"TOCFL-MultiBench/TOCFL-MultiBench.json\"\n",
    "    prompt_template_path = \"prompt/base.txt\"\n",
    "    model_name_or_path = \"Qwen/Qwen2.5-Omni-3B\" # str[\"Qwen/Qwen2.5-Omni-7B\" | \"Qwen/Qwen2.5-Omni-3B\"]\n",
    "    #tensor_type = \"bf16\" # \"bf16\", \"auto\"\n",
    "    \n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    dataset = load_data(dataset_name_or_path, prompt_template_path)\n",
    "    print(f\"Dataset loaded: {dataset}\")\n",
    "    \n",
    "    \"\"\" Load model \"\"\"\n",
    "    model, processor = load_model(model_name_or_path)\n",
    "    \n",
    "    \"\"\" Evaluation \"\"\"\n",
    "    for data in tqdm(dataset, desc=\"Running inference\", unit=\"example\"): \n",
    "        \"\"\" Load Template: 在 dataset 加入一個欄位叫做 template_response \"\"\"\n",
    "        chat_template = get_template_response(image_path=data[\"image\"], audio_path=data[\"audio\"], question=data[\"question\"])\n",
    "        text_prompt_vc = processor.apply_chat_template(chat_template, add_generation_prompt=True, tokenize=False)\n",
    "        audios_vc, image_vc, _ = process_mm_info(conversation_voice_chat, use_audio_in_video=USE_AUDIO_IN_VIDEO_FLAG)\n",
    "        inputs_math = processor(\n",
    "            text=text_prompt_vc, audio=audios_vc, images=image_vc,\n",
    "            return_tensors=\"pt\", padding=True,\n",
    "            #use_audio_in_video=USE_AUDIO_IN_VIDEO_FLAG\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(11207330)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bfef332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 900/900 [00:00<00:00, 7738.06example/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': [{'audio': None,\n",
       "    'image': None,\n",
       "    'text': 'You are Qwen, a virtual human developed by the Qwen Team...',\n",
       "    'type': 'text'}],\n",
       "  'role': 'system'},\n",
       " {'content': [{'audio': None,\n",
       "    'image': None,\n",
       "    'text': \"在這個部分，你會看到一張圖片。請根據圖片，從（A）（B）（C）三個選項中選出與圖片內容相符的句子。\\n他們在哪裡？\\n（A）銀行（B）教室（C）郵局\\n僅輸出正確答案的字母，格式必須為 'A', 'B', 'C', 'D'，輸出限制為單個字母，無需解釋。\",\n",
       "    'type': 'text'},\n",
       "   {'audio': None, 'image': None, 'text': None, 'type': 'audio'},\n",
       "   {'audio': None,\n",
       "    'image': 'TOCFL-MultiBench/images/01-L-A-P1-001.png',\n",
       "    'text': None,\n",
       "    'type': 'image'}],\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_template_response(image_path: str, audio_path: str, question: str) -> list:\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are Qwen, a virtual human developed by the Qwen Team...\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    user_content = [] # List[Dict[str, Any]]\n",
    "    user_content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": question\n",
    "    })\n",
    "    \n",
    "    if audio_path != \"\":\n",
    "        user_content.append({\n",
    "            \"type\": \"audio\",\n",
    "            \"audio\": audio_path\n",
    "        })\n",
    "    if image_path != \"\":\n",
    "        user_content.append({\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image_path\n",
    "        })\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_content\n",
    "    }\n",
    "    \n",
    "    return [system_msg, user_msg]\n",
    "\n",
    "def load_data(dataset_name_or_path: str, \n",
    "              prompt_template_path: str = None):\n",
    "    \"\"\" Init: multiple choices answer \"\"\"\n",
    "    all_choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    \n",
    "    \"\"\" Init: prompt template\"\"\"\n",
    "    if prompt_template_path is not None:\n",
    "        try:\n",
    "            with Path(prompt_template_path).open(\"r\", encoding=\"utf-8\") as file:\n",
    "                prompt_template = file.read()\n",
    "        except (FileNotFoundError, IOError) as e:\n",
    "            raise RuntimeError(f\"Failed to load the prompt template: {e}\") from e\n",
    "    else:\n",
    "        prompt_template = \"{question}\"\n",
    "\n",
    "    \n",
    "    \"\"\" preprocess function: use the prompt template to format the question \"\"\"\n",
    "    def _preprocess(example):\n",
    "        example[\"question\"] = (\n",
    "            f\"{example['instruction']}\\n\"\n",
    "            + f\"{example['question']}\\n\"\n",
    "            + \"\".join(example[f\"option{i + 1}\"] for i in range(len(all_choices)))\n",
    "        )\n",
    "        example[\"answer\"] = example[\"answer\"].replace(\"A\", \"0\").replace(\"B\", \"1\").replace(\"C\", \"2\").replace(\"D\", \"3\") # anwer to index: 這邊是用 0,1,2,3來表示答案\n",
    "        example[\"question\"] = prompt_template.format(question=example[\"question\"])\n",
    "        \n",
    "        example[\"template_prompt\"] = get_template_response(\n",
    "            image_path=example[\"image\"],\n",
    "            audio_path=example[\"audio\"],\n",
    "            question=example[\"question\"]\n",
    "        )\n",
    "        \n",
    "        return example\n",
    "    \n",
    "    dataset = load_dataset(\n",
    "                    \"json\",\n",
    "                    data_files=dataset_name_or_path,\n",
    "                    split=\"train\",\n",
    "                )\n",
    "    \n",
    "    return_dataset = Dataset.from_list([\n",
    "                _preprocess(example)\n",
    "                for example in tqdm(dataset, desc=\"Processing dataset\", unit=\"example\")\n",
    "            ])\n",
    "    \n",
    "    return return_dataset\n",
    "\n",
    "data = load_data(dataset_name_or_path=\"TOCFL-MultiBench/TOCFL-MultiBench.json\", prompt_template_path=\"prompt/base.txt\")\n",
    "data[\"template_prompt\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {'content': [{'audio': None,\n",
    "    'image': None,\n",
    "    'text': 'You are Qwen, a virtual human developed by the Qwen Team...',\n",
    "    'type': 'text'}],\n",
    "  'role': 'system'},\n",
    " {'content': [{'audio': None,\n",
    "    'image': 'TOCFL-MultiBench/images/01-L-A-P1-001.png',\n",
    "    'text': None,\n",
    "    'type': 'image'},\n",
    "   {'audio': None,\n",
    "    'image': None,\n",
    "    'text': \"在這個部分，你會看到一張圖片。請根據圖片，從（A）（B）（C）三個選項中選出與圖片內容相符的句子。\\n他們在哪裡？\\n（A）銀行（B）教室（C）郵局\\n僅輸出正確答案的字母，格式必須為 'A', 'B', 'C', 'D'，輸出限制為單個字母，無需解釋。\",\n",
    "    'type': 'text'}],\n",
    "  'role': 'user'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c11633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" metrics\"\"\"\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def calculate_metrics(\n",
    "    all_choices: list,\n",
    "    all_answers: list,\n",
    "    all_response: list,\n",
    "    all_index2ans: list = None,\n",
    "    allow_random: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"calculate_metrics\"\"\"\n",
    "    if all_index2ans is None:\n",
    "        all_index2ans = [None] * len(all_response)\n",
    "\n",
    "    predictions = [\n",
    "        parse_multi_choice_response(response, all_choices, index2ans, allow_random)\n",
    "        for response, index2ans in zip(all_response, all_index2ans)\n",
    "    ]\n",
    "\n",
    "    accuracy = accuracy_score(all_answers, predictions)\n",
    "    f1 = f1_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "    precision = precision_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "    recall = recall_score(all_answers, predictions, average=\"weighted\", zero_division=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "def parse_multi_choice_response(\n",
    "    response: str,\n",
    "    all_choices: list = [\"A\", \"B\", \"C\", \"D\"],\n",
    "    index2ans: dict = None,\n",
    "    allow_random: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"parse_multi_choice_response\"\"\"\n",
    "    for char in [',', '.', '!', '?', ';', ':', \"'\"]:\n",
    "        response = response.strip(char)\n",
    "    response = \" \" + response + \" \"\n",
    "\n",
    "    index_ans = True\n",
    "    ans_with_brack = False\n",
    "    candidates = []\n",
    "    for choice in all_choices:\n",
    "        if f'({choice})' in response:\n",
    "            candidates.append(choice)\n",
    "            ans_with_brack = True\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        for choice in all_choices:\n",
    "            if f' {choice} ' in response:\n",
    "                candidates.append(choice)\n",
    "\n",
    "    if index2ans is not None and len(candidates) == 0 and len(response.split()) > 5:\n",
    "        for index, ans in index2ans.items():\n",
    "            if ans and ans.lower() in response.lower():\n",
    "                candidates.append(index)\n",
    "                index_ans = False\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        if allow_random:\n",
    "            pred_index = random.choice(all_choices)\n",
    "        else:\n",
    "            pred_index = \"\"\n",
    "\n",
    "    elif len(candidates) > 1:\n",
    "        start_indexes = []\n",
    "        if index_ans:\n",
    "            if ans_with_brack:\n",
    "                for can in candidates:\n",
    "                    index = response.rfind(f'({can})')\n",
    "                    start_indexes.append(index)\n",
    "            else:\n",
    "                for can in candidates:\n",
    "                    index = response.rfind(f\" {can} \")\n",
    "                    start_indexes.append(index)\n",
    "        else:\n",
    "            for can in candidates:\n",
    "                index = response.lower().rfind(index2ans[can].lower())\n",
    "                start_indexes.append(index)\n",
    "\n",
    "        pred_index = candidates[np.argmax(start_indexes)]\n",
    "    else:\n",
    "        pred_index = candidates[0]\n",
    "\n",
    "    return pred_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479196d7",
   "metadata": {},
   "source": [
    "### Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa80797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(dataset_name_or_path=\"TOCFL-MultiBench/TOCFL-MultiBench.json\", prompt_template_path=\"prompt/base.txt\")\n",
    "\n",
    "\"\"\" Usage: 問題底家 \"\"\"\n",
    "print(data)\n",
    "print(data['question'])\n",
    "print(data['answer']) # answer 被弄成數值，以搭配calculate_metrics。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003485af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定義可選項目（模型可能輸出的 label）\n",
    "all_choices   = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# 2. 定義「正確答案」列表（ground truth）\n",
    "#    比方說我們有四題，正確答案分別是 A, B, C, A\n",
    "all_answers   = [\"A\", \"B\", \"C\", \"A\"]\n",
    "\n",
    "# 3. 定義模型回傳的「原始字串」列表\n",
    "#    這裡假設模型回了跟正確一樣的 four responses\n",
    "all_response  = [\"A\", \"B\", \"C\", \"A\"]\n",
    "\n",
    "# 4. （選擇性）定義 index2ans 映射\n",
    "#    當模型回的是文字（例如 \"dog\"、\"cat\"）而非 A/B/C/D 時，用這個 dict 幫它對回標籤。\n",
    "#    key 是選項字母，value 是對應的文字答案。\n",
    "#    如果你的模型只回 A/B/C/D，就可以不傳這個參數（預設會是全 None）。\n",
    "all_index2ans = None\n",
    "\n",
    "# 呼叫 calculate_metrics\n",
    "metrics = calculate_metrics(\n",
    "    all_choices=all_choices,\n",
    "    all_answers=all_answers,\n",
    "    all_response=all_response,\n",
    "    all_index2ans=all_index2ans,\n",
    "    allow_random=True,         # 若 parse 不出答案，是否隨機選一個\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
